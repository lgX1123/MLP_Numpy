{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 520556528"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './Assignment1-Dataset/'\n",
    "\n",
    "train_X = np.load(file_path + 'train_data.npy')\n",
    "train_y = np.load(file_path + 'train_label.npy')\n",
    "test_X = np.load(file_path + 'test_data.npy')\n",
    "test_y = np.load(file_path + 'test_label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 128)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([train_y[i][0] for i in range(train_y.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.85672763,  1.89363852, -0.25110738, -1.09727424],\n",
       "       [-0.23227008, -0.11473912, -1.69045798,  1.31190671],\n",
       "       [ 1.44085915,  0.37027676, -0.38280027,  0.4089585 ]])"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array = np.random.randn(3, 4)\n",
    "test_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time:  Tue Mar  5 19:06:31 2024\n",
      "End time:  Tue Mar  5 19:06:32 2024\n",
      "test_fun executed in 1.0050 seconds\n"
     ]
    }
   ],
   "source": [
    "def timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print('Start time: ', time.ctime())\n",
    "        start_time = time.time()  # start time\n",
    "\n",
    "        result = func(*args, **kwargs)  # run\n",
    "\n",
    "        end_time = time.time()  # end time\n",
    "        print('End time: ', time.ctime())\n",
    "        print(f\"{func.__name__} executed in {(end_time - start_time):.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@timer\n",
    "def test_fun(x):\n",
    "    time.sleep(x)\n",
    "\n",
    "test_fun(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaiming Init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer from https://github.com/pytorch/pytorch/blob/main/torch/nn/init.py.\n",
    "\n",
    "Modify tensor to np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.49463193,  1.09329271, -0.14497691, -0.63351158, -0.13410119,\n",
       "        -0.06624466],\n",
       "       [-0.97598637,  0.75742969,  0.83188042,  0.21377939, -0.22100984,\n",
       "         0.2361123 ],\n",
       "       [-0.45850532,  0.58140505,  0.29454185,  0.1586542 ,  0.71893752,\n",
       "        -0.0909816 ],\n",
       "       [ 0.13477889,  0.27962191, -0.11743695, -0.07979469,  0.12256677,\n",
       "        -0.55592582],\n",
       "       [-0.290316  , -0.08481382, -0.53662092,  0.0805716 ,  0.21629346,\n",
       "        -0.8638151 ]])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_gain(nonlinearity, param=None):\n",
    "    r\"\"\"Return the recommended gain value for the given nonlinearity function.\n",
    "    The values are as follows:\n",
    "\n",
    "    ================= ====================================================\n",
    "    nonlinearity      gain\n",
    "    ================= ====================================================\n",
    "    Linear / Identity :math:`1`\n",
    "    Conv{1,2,3}D      :math:`1`\n",
    "    Sigmoid           :math:`1`\n",
    "    Tanh              :math:`\\frac{5}{3}`\n",
    "    ReLU              :math:`\\sqrt{2}`\n",
    "    Leaky Relu        :math:`\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}`\n",
    "    SELU              :math:`\\frac{3}{4}`\n",
    "    ================= ====================================================\n",
    "    \"\"\"\n",
    "    \n",
    "    if nonlinearity == 'sigmoid':\n",
    "        return 1\n",
    "    elif nonlinearity == 'tanh':\n",
    "        return 5.0 / 3\n",
    "    elif nonlinearity == 'relu':\n",
    "        return math.sqrt(2.0)\n",
    "    elif nonlinearity == 'leaky_relu':\n",
    "        if param is None:\n",
    "            negative_slope = 0.01\n",
    "        elif not isinstance(param, bool) and isinstance(param, int) or isinstance(param, float):\n",
    "            # True/False are instances of int, hence check above\n",
    "            negative_slope = param\n",
    "        else:\n",
    "            raise ValueError(f\"negative_slope {param} not a valid number\")\n",
    "        return math.sqrt(2.0 / (1 + negative_slope ** 2))\n",
    "    elif nonlinearity == 'selu':\n",
    "        return 3.0 / 4  # Value found empirically (https://github.com/pytorch/pytorch/pull/50664)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported nonlinearity {nonlinearity}\")\n",
    "\n",
    "def _calculate_fan_in_and_fan_out(array):\n",
    "    dimensions = len(array.shape)\n",
    "    if dimensions < 2:\n",
    "        raise ValueError(\"Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\")\n",
    "\n",
    "    num_input_fmaps = array.shape[1]\n",
    "    num_output_fmaps = array.shape[0]\n",
    "    receptive_field_size = 1\n",
    "    if dimensions > 2:\n",
    "        # math.prod is not always available, accumulate the product manually\n",
    "        # we could use functools.reduce but that is not supported by TorchScript\n",
    "        for s in array.shape[2:]:\n",
    "            receptive_field_size *= s\n",
    "    fan_in = num_input_fmaps * receptive_field_size\n",
    "    fan_out = num_output_fmaps * receptive_field_size\n",
    "\n",
    "    return fan_in, fan_out\n",
    "\n",
    "def _calculate_correct_fan(array, mode):\n",
    "    mode = mode.lower()\n",
    "    valid_modes = ['fan_in', 'fan_out']\n",
    "    if mode not in valid_modes:\n",
    "        raise ValueError(f\"Mode {mode} not supported, please use one of {valid_modes}\")\n",
    "\n",
    "    fan_in, fan_out = _calculate_fan_in_and_fan_out(array)\n",
    "    return fan_in if mode == 'fan_in' else fan_out\n",
    "\n",
    "def kaiming_normal_(array: np.array, a: float = 0, mode: str = 'fan_in', nonlinearity: str = 'leaky_relu'):\n",
    "    fan = _calculate_correct_fan(array, mode)\n",
    "    gain = calculate_gain(nonlinearity, a)\n",
    "    std = gain / math.sqrt(fan)\n",
    "    return np.random.normal(0, std, array.shape)\n",
    "    \n",
    "\n",
    "kaiming_normal_(np.array([0] * 30).reshape(5, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameter(object):\n",
    "    def __init__(self, data, requires_grad, skip_decay=False):\n",
    "        self.data = data\n",
    "        self.grad = None\n",
    "        self.skip_decay = skip_decay\n",
    "        self.requires_grad = requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target):\n",
    "    preds = output.argmax(axis=-1, keepdims=True)\n",
    "    return np.mean(preds == target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    def __init__(self, name, requires_grad=False):\n",
    "        self.name = name \n",
    "        self.requires_grad = requires_grad\n",
    "        \n",
    "    def forward(self, *args):\n",
    "        pass\n",
    "\n",
    "    def backward(self, *args):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.89363852, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.31190671],\n",
       "       [1.44085915, 0.37027676, 0.        , 0.4089585 ]])"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class relu(Layer):\n",
    "    def __init__(self, name, requires_grad=False):\n",
    "        super().__init__(name, requires_grad)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return np.maximum(0, input)\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        grad_output[self.input <= 0] = 0\n",
    "        return grad_output\n",
    "    \n",
    "\n",
    "test_relu = relu('test_relu')\n",
    "_ = test_relu.forward(test_array)\n",
    "test_relu.backward(test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sigmoid(Layer):\n",
    "    def __init__(self, name, requires_grad=False):\n",
    "        super().__init__(name, requires_grad)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        self.y = 1. / (1. + np.exp(-input))   # save sigmoid for more convenient grad computation\n",
    "        return self.y\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        return self.y * (1 - self.y) * grad_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10369682, 0.68890954, 0.10369682, 0.10369682],\n",
       "       [0.14895921, 0.14895921, 0.14895921, 0.55312236],\n",
       "       [0.5165657 , 0.17708327, 0.12228365, 0.18406737]])"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class softmax(Layer):\n",
    "    def __init__(self, name, requires_grad=False):\n",
    "        super().__init__(name, requires_grad)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "            input.shape = [batch size, num_class]\n",
    "        \"\"\"\n",
    "        x_max = input.max(axis=-1, keepdims=True)       # to avoid overflow\n",
    "        x_exp = np.exp(input - x_max)\n",
    "        return x_exp / x_exp.sum(axis=-1, keepdims=True)\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        # packaged in CrossEntropyLoss\n",
    "        return grad_output\n",
    "\n",
    "softmax('test_softmax').forward(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: more activation, tanh, gelu, leaky_relu ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenLayer(Layer):\n",
    "    def __init__(self, name, in_num, out_num):\n",
    "        super().__init__(name, requires_grad=True)\n",
    "        self.in_num = in_num\n",
    "        self.out_num = out_num\n",
    "\n",
    "        W = kaiming_normal_(np.array([0] * in_num * out_num).reshape(in_num, out_num), a=math.sqrt(5))     # Kaiming Init\n",
    "        self.W = Parameter(W, self.requires_grad)\n",
    "        self.b = Parameter(np.zeros(out_num), self.requires_grad)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return input @ self.W.data + self.b.data      # [batch size, in_num] @ [in_num, out_num] + [out_num] => [batch size, out_num]\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "            grad_output: [batch size, out_num]\n",
    "        \"\"\"\n",
    "        batch_size = grad_output.shape[0]\n",
    "        self.W.grad = self.input.T @ grad_output / batch_size\n",
    "        self.b.grad = grad_output.sum(axis=0) / batch_size\n",
    "        return grad_output @ self.W.data.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss(object):\n",
    "    def __init__(self):\n",
    "        self.softmax = softmax('softmax')\n",
    "    \n",
    "    def gradient(self):\n",
    "        return self.grad\n",
    "\n",
    "    def __call__(self, input, ground_truth):\n",
    "        self.grad = input - ground_truth    #TODO: 推导要写在report上不？\n",
    "        \n",
    "        preds = self.softmax.forward(input)\n",
    "\n",
    "        bacth_size = input.shape[0]\n",
    "        loss = -1 * (ground_truth * np.log(preds)).sum() / bacth_size\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(object):\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.params = []\n",
    "        self.num_layers = 0\n",
    "    \n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        if layer.requires_grad:\n",
    "            self.params.append(layer.W)\n",
    "            self.params.append(layer.b)\n",
    "        self.num_layers += 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, x):\n",
    "        for layer in self.layers[::-1]:\n",
    "            x = layer.backward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD with Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(object):\n",
    "    def __init__(self, parameters, momentum, lr, weight_decay):\n",
    "        self.parameters = parameters\n",
    "        self.momentum = momentum\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.v = [np.zeros(p.data.shape) for p in self.parameters]\n",
    "\n",
    "    def step(self):\n",
    "        for i, (v, p) in enumerate(zip(self.v, self.parameters)):\n",
    "            p.data *= self.weight_decay\n",
    "            v = self.momentum * v - self.lr * p.grad\n",
    "            self.v[i] = v\n",
    "            p.data -= self.v[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineLR(object):\n",
    "    def __init__(self, optimizer, T_max):\n",
    "        self.optimizer = optimizer\n",
    "        self.T_max = T_max\n",
    "        self.n = -1\n",
    "        self.base_lr = optimizer.lr\n",
    "        self.step()\n",
    "\n",
    "    def step(self):\n",
    "        self.n += 1\n",
    "        lr = self.get_lr()\n",
    "        self.optimizer.lr = lr\n",
    "\n",
    "    def get_lr(self):\n",
    "        cos = np.cos(np.pi * self.n / self.T_max)\n",
    "        return self.base_lr * (1 + cos) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, config, model=None, train_loader=None, val_loader=None):\n",
    "        self.config = config\n",
    "        self.epochs = self.config['epoch']\n",
    "        self.lr = self.config['lr']\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "\n",
    "        self.criterion = CrossEntropyLoss()\n",
    "        self.optimizer = SGD(self.model.params, self.config['momentum'], self.lr, self.config['weight_decay'])\n",
    "        self.train_scheduler = CosineLR(self.optimizer, T_max=self.epochs)\n",
    "\n",
    "    def train(self):\n",
    "        best_acc1 = 0\n",
    "        for epoch in range(self.epochs):\n",
    "            print('current lr {:.5e}'.format(self.optimizer.lr))\n",
    "            self.train_per_epoch(epoch)\n",
    "            self.train_scheduler.step()\n",
    "\n",
    "            # evaluate on validation set\n",
    "            acc1 = self.validate(epoch)\n",
    "\n",
    "            # remember best prec@1\n",
    "            best_acc1 = max(acc1, best_acc1)\n",
    "            output_best = 'Best Prec@1: %.3f\\n' % (best_acc1)\n",
    "            print(output_best)\n",
    "\n",
    "    \n",
    "    def train_per_epoch(self, epoch):\n",
    "        batch_time = AverageMeter()\n",
    "        data_time = AverageMeter()\n",
    "        losses = AverageMeter()\n",
    "        top1 = AverageMeter()\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        for i, (input, target) in enumerate(self.train_loader):\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            # compute output\n",
    "            output = self.model.forward(input)\n",
    "            loss = self.criterion(output, target)\n",
    "\n",
    "            # compute gradient and do SGD step\n",
    "            self.model.backward(self.criterion.grad)\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1 = accuracy(output, target)\n",
    "            losses.update(loss, input.shape[0])\n",
    "            top1.update(prec1, input.shape[0])\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                    'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                    'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                    'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                    'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                        epoch, i, len(self.train_loader), batch_time=batch_time,\n",
    "                        data_time=data_time, loss=losses, top1=top1))\n",
    "                \n",
    "    def validate(self, epoch):\n",
    "        batch_time = AverageMeter()\n",
    "        losses = AverageMeter()\n",
    "        top1 = AverageMeter()\n",
    "\n",
    "        end = time.time()\n",
    "        for i, (input, target) in enumerate(self.val_loader):\n",
    "            # compute output\n",
    "            output = self.model.forward(input)\n",
    "            loss = self.criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1 = accuracy(output, target)\n",
    "            losses.update(loss, input.shape[0])\n",
    "            top1.update(prec1, input.shape[0])\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                    'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                    'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                    'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                        i, len(self.val_loader), batch_time=batch_time, loss=losses,\n",
    "                        top1=top1))\n",
    "        \n",
    "        output = ('EPOCH: {epoch} {flag} Results: Prec@1 {top1.avg:.3f} '.format(epoch=epoch + 1 , flag='val', top1=top1))\n",
    "\n",
    "        return top1.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader(object):\n",
    "    def __init__(self, X, y, batch_size, shuffle=True, seed=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.seed = seed\n",
    "        self.index = np.arange(X.shape[0])\n",
    "    \n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            if self.seed is not None:\n",
    "                np.random.seed(self.seed)\n",
    "            np.random.shuffle(self.index)\n",
    "        self.n = 0\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.n >= len(self.index):\n",
    "            raise StopIteration\n",
    "        \n",
    "        index = self.index[self.n:self.n + self.batch_size]\n",
    "        batch_X = self.X[index]\n",
    "        batch_y = self.y[index]\n",
    "        self.n += self.batch_size\n",
    "\n",
    "        return batch_X, batch_y\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "            num of batch\n",
    "        \"\"\"\n",
    "        return (len(self.index) + self.batch_size - 1) // self.batch_size  # ceiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(layers):\n",
    "    model = MLP()\n",
    "    str2obj = {\n",
    "        'linear': HiddenLayer, \n",
    "        'relu': relu, \n",
    "        'sigmoid': sigmoid, \n",
    "        'softmax': softmax,\n",
    "    }\n",
    "    for i in layers:\n",
    "        model.add_layer(str2obj[i['type']](**i['params']))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current lr 1.00000e-01\n",
      "Epoch: [0][0/391]\tTime 0.002 (0.002)\tData 0.001 (0.001)\tLoss 101.7966 (101.7966)\tPrec@1 0.109 (0.109)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][100/391]\tTime 0.004 (0.010)\tData 0.000 (0.000)\tLoss 109.5136 (105.8334)\tPrec@1 0.078 (0.102)\n",
      "Epoch: [0][200/391]\tTime 0.001 (0.007)\tData 0.000 (0.000)\tLoss 98.4682 (106.4756)\tPrec@1 0.125 (0.100)\n",
      "Epoch: [0][300/391]\tTime 0.000 (0.005)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.094 (0.100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ws/v9bt5j3d5tv4mvh9bdr1h2ym0000gn/T/ipykernel_14794/2044648914.py:13: RuntimeWarning: overflow encountered in matmul\n",
      "  return input @ self.W.data + self.b.data      # [batch size, in_num] @ [in_num, out_num] + [out_num] => [batch size, out_num]\n",
      "/var/folders/ws/v9bt5j3d5tv4mvh9bdr1h2ym0000gn/T/ipykernel_14794/1005250544.py:10: RuntimeWarning: invalid value encountered in subtract\n",
      "  x_exp = np.exp(input - x_max)\n",
      "/var/folders/ws/v9bt5j3d5tv4mvh9bdr1h2ym0000gn/T/ipykernel_14794/2044648914.py:22: RuntimeWarning: overflow encountered in matmul\n",
      "  return grad_output @ self.W.data.T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/79]\tTime 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.102 (0.102)\n",
      "Best Prec@1: 0.100\n",
      "\n",
      "current lr 9.75528e-02\n",
      "Epoch: [1][0/391]\tTime 0.001 (0.001)\tData 0.001 (0.001)\tLoss nan (nan)\tPrec@1 0.094 (0.094)\n",
      "Epoch: [1][100/391]\tTime 0.009 (0.001)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.094 (0.099)\n",
      "Epoch: [1][200/391]\tTime 0.000 (0.001)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.102 (0.098)\n",
      "Epoch: [1][300/391]\tTime 0.001 (0.001)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.086 (0.099)\n",
      "Test: [0/79]\tTime 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.102 (0.102)\n",
      "Best Prec@1: 0.100\n",
      "\n",
      "current lr 9.04508e-02\n",
      "Epoch: [2][0/391]\tTime 0.008 (0.008)\tData 0.001 (0.001)\tLoss nan (nan)\tPrec@1 0.117 (0.117)\n",
      "Epoch: [2][100/391]\tTime 0.000 (0.001)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.094 (0.103)\n",
      "Epoch: [2][200/391]\tTime 0.000 (0.001)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.102 (0.103)\n",
      "Epoch: [2][300/391]\tTime 0.000 (0.001)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.055 (0.101)\n",
      "Test: [0/79]\tTime 0.001 (0.001)\tLoss nan (nan)\tPrec@1 0.102 (0.102)\n",
      "Best Prec@1: 0.100\n",
      "\n",
      "current lr 7.93893e-02\n",
      "Epoch: [3][0/391]\tTime 0.001 (0.001)\tData 0.001 (0.001)\tLoss nan (nan)\tPrec@1 0.109 (0.109)\n",
      "Epoch: [3][100/391]\tTime 0.001 (0.001)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.094 (0.101)\n",
      "Epoch: [3][200/391]\tTime 0.000 (0.001)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.117 (0.101)\n",
      "Epoch: [3][300/391]\tTime 0.000 (0.001)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.117 (0.101)\n",
      "Test: [0/79]\tTime 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.102 (0.102)\n",
      "Best Prec@1: 0.100\n",
      "\n",
      "current lr 6.54508e-02\n",
      "Epoch: [4][0/391]\tTime 0.001 (0.001)\tData 0.001 (0.001)\tLoss nan (nan)\tPrec@1 0.086 (0.086)\n",
      "Epoch: [4][100/391]\tTime 0.001 (0.000)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.062 (0.100)\n",
      "Epoch: [4][200/391]\tTime 0.000 (0.000)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.086 (0.100)\n",
      "Epoch: [4][300/391]\tTime 0.001 (0.001)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.109 (0.100)\n",
      "Test: [0/79]\tTime 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.102 (0.102)\n",
      "Best Prec@1: 0.100\n",
      "\n",
      "current lr 5.00000e-02\n",
      "Epoch: [5][0/391]\tTime 0.001 (0.001)\tData 0.001 (0.001)\tLoss nan (nan)\tPrec@1 0.133 (0.133)\n",
      "Epoch: [5][100/391]\tTime 0.000 (0.000)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.094 (0.100)\n",
      "Epoch: [5][200/391]\tTime 0.000 (0.001)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.125 (0.101)\n",
      "Epoch: [5][300/391]\tTime 0.000 (0.001)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.094 (0.100)\n",
      "Test: [0/79]\tTime 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.102 (0.102)\n",
      "Best Prec@1: 0.100\n",
      "\n",
      "current lr 3.45492e-02\n",
      "Epoch: [6][0/391]\tTime 0.001 (0.001)\tData 0.001 (0.001)\tLoss nan (nan)\tPrec@1 0.078 (0.078)\n",
      "Epoch: [6][100/391]\tTime 0.000 (0.001)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.109 (0.102)\n",
      "Epoch: [6][200/391]\tTime 0.000 (0.001)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.102 (0.101)\n",
      "Epoch: [6][300/391]\tTime 0.000 (0.001)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.109 (0.101)\n",
      "Test: [0/79]\tTime 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.102 (0.102)\n",
      "Best Prec@1: 0.100\n",
      "\n",
      "current lr 2.06107e-02\n",
      "Epoch: [7][0/391]\tTime 0.001 (0.001)\tData 0.001 (0.001)\tLoss nan (nan)\tPrec@1 0.117 (0.117)\n",
      "Epoch: [7][100/391]\tTime 0.000 (0.001)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.117 (0.100)\n",
      "Epoch: [7][200/391]\tTime 0.000 (0.000)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.102 (0.100)\n",
      "Epoch: [7][300/391]\tTime 0.000 (0.000)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.102 (0.101)\n",
      "Test: [0/79]\tTime 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.102 (0.102)\n",
      "Best Prec@1: 0.100\n",
      "\n",
      "current lr 9.54915e-03\n",
      "Epoch: [8][0/391]\tTime 0.001 (0.001)\tData 0.001 (0.001)\tLoss nan (nan)\tPrec@1 0.078 (0.078)\n",
      "Epoch: [8][100/391]\tTime 0.000 (0.000)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.102 (0.097)\n",
      "Epoch: [8][200/391]\tTime 0.000 (0.001)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.102 (0.099)\n",
      "Epoch: [8][300/391]\tTime 0.000 (0.001)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.078 (0.099)\n",
      "Test: [0/79]\tTime 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.102 (0.102)\n",
      "Best Prec@1: 0.100\n",
      "\n",
      "current lr 2.44717e-03\n",
      "Epoch: [9][0/391]\tTime 0.002 (0.002)\tData 0.001 (0.001)\tLoss nan (nan)\tPrec@1 0.094 (0.094)\n",
      "Epoch: [9][100/391]\tTime 0.001 (0.000)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.094 (0.104)\n",
      "Epoch: [9][200/391]\tTime 0.000 (0.000)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.109 (0.103)\n",
      "Epoch: [9][300/391]\tTime 0.000 (0.001)\tData 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.086 (0.101)\n",
      "Test: [0/79]\tTime 0.000 (0.000)\tLoss nan (nan)\tPrec@1 0.102 (0.102)\n",
      "Best Prec@1: 0.100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layers = [\n",
    "    {'type': 'linear', 'params': {'name': 'fc1', 'in_num': 128, 'out_num': 64}},\n",
    "    {'type': 'relu', 'params': {'name': 'relu1'}}, \n",
    "    {'type': 'linear', 'params': {'name': 'fc2', 'in_num': 64, 'out_num': 10}},\n",
    "    {'type': 'softmax', 'params': {'name': 'softmax'}}\n",
    "]\n",
    "lr = 0.1\n",
    "bs = 128\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-3     # 2e-4, 1e-4\n",
    "seed = 0\n",
    "epoch = 10\n",
    "\n",
    "config = {\n",
    "    'layers': layers,\n",
    "    'lr': lr, \n",
    "    'bs': bs,\n",
    "    'momentum': momentum,\n",
    "    'weight_decay': weight_decay,\n",
    "    'seed': seed,\n",
    "    'epoch': epoch,\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "train_dataloader = Dataloader(train_X, train_y, config['bs'], shuffle=True, seed=config['seed'])\n",
    "test_dataloader = Dataloader(test_X, test_y, config['bs'], shuffle=False)\n",
    "model = get_model(config['layers'])\n",
    "trainer = Trainer(config, model, train_dataloader, test_dataloader)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
